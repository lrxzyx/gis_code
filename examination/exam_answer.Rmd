
# Originality declaration  

I, [**Ruixuan Li**], confirm that the work presented in this assessment is my own. Where information has been derived from other sources, I confirm that this has been indicated in the work.

# Start your response here
Title: "Analysis Report: Spatial Patterns of Very Healthy People in Manchester"
Author: "[Ruixuan Li]"
Date: "13th December 2024"


```{r load libraries}
library(readr)
library(ggplot2)
library(sf)
library(dplyr)
library(spdep)
library(spatstat)
library(sp)
library(tmap)
library(tmaptools)
library(janitor)
library(tidyverse)
```

```{r data reading}
census_health <- read_csv("/Users/liruixuan/Desktop/UCL/GIS/examination/examination/census2021-ts037-lsoa.csv",na=c(" "))

boundary <- st_read("/Users/liruixuan/Desktop/UCL/GIS/examination/examination/Lower_layer_Super_Output_Areas_December_2021_Boundaries_EW_BFC_V10/Lower_layer_Super_Output_Areas_December_2021_Boundaries_EW_BFC_V10.shp")

```
data:
LSOA (Lower Layer Super Output Area) 2021
'Boundary' data is too large to upload:
https://geoportal.statistics.gov.uk/datasets/2bbaef5230694f3abae4f9145a3a9800_0/explore  (shapefile) I removed all parentheses from the file name for easy reading of data

```{r}
#View the first few lines of data to understand the structure
head(census_health)
```


```{r Merge two data}
merged_data <- boundary %>%
  left_join(census_health, by = c("LSOA21CD" = "geography code"))
```

```{r}
colnames(merged_data)
```

```{r filter data}
#Filter out Manchester data
manchester_data <- merged_data %>%
  filter(grepl("Manchester", LSOA21NM, ignore.case = TRUE))
```

```{r select data}
#Filter out very healthy data
manchester_data_very <- manchester_data %>%
  select(-"General health: Good health",-"General health: Fair health",
         -"General health: Bad health",-"General health: Very bad health")
```



```{r tmap}
#Create a map
tm_shape(manchester_data_very) +
  tm_polygons("General health: Total: All usual residents", 
              title = "Health Status in Manchester") +
  tm_layout(main.title = "Very Health people in Manchester")
```

```{r}
window <- as.owin(manchester_data_very) 
plot(window)
```
```{r create a sp objec}
manchester_data_very_sp <- manchester_data_very %>%
  as(.,"Spatial")
```

```{r create a ppp object}
library(spatstat)

#Extract the centroid of a polygon as a point
centroids <- coordinates(manchester_data_very_sp)  #Extract centroid coordinates

#Create observation window (corrected to spatstat format)
bounding_box <- bbox(manchester_data_very_sp)  #Extract boundary range
window <- owin(xrange = bounding_box[1,], yrange = bounding_box[2,])  # 

#Create Point Pattern Object (PPP)
manchester_data_very_sp_ppp <- ppp(x = centroids[, 1], 
                              y = centroids[, 2], 
                              window = window)

#View point mode results
summary(manchester_data_very_sp_ppp)

#Visualization
plot(manchester_data_very_sp_ppp, main = "Point Pattern of Manchester Data")
```
I really don't know how to create its coordinate points, so the solution GPT gave me is to use the centroid method.

```{r Ripleyâ€™s K}
K <- manchester_data_very_sp_ppp %>%
  Kest(.,correction="border") %>%
  plot()
```
The theoretical standard is the red straight line, which shows how the points should be spread out if they were randomly chosen.The steady black line shows the real pattern of observations and the real trend of point distribution;In the Manchester health data, the real points are more closely spaced than the random distribution, as shown by the fact that the black line is higher than the red line.Clustering is seen within the range of r.

```{r Kernel Density Estimation}
manchester_data_very_sp_ppp%>%
  density(., sigma=500) %>%
  plot()
```

Blue is a low-density area (with sparse point distribution). Yellow is a high-density area (with concentrated point distribution). The yellow areas are hotspots, indicating that health data is gathered in these locations, such as areas where self-reported health status may be more prominent. The blue areas with low density indicate that the distribution of health data in these areas is relatively small or scattered.

```{r Quadrat Analysis}
#First plot the points
plot(manchester_data_very_sp_ppp,
     pch=16,
     cex=0.5, 
     main="Blue Plaques in Harrow")

#now count the points in that fall in a 6 x 6
#grid overlaid across the windowBluePlaquesSub.ppp2<-BluePlaquesSub.ppp %>%
manchester_data_very_sp_ppp %>%
  quadratcount(.,nx = 6, ny = 6)%>%
    plot(., add=T, col="red")
```

```{r}
#run the quadrat count
Qcount <- manchester_data_very_sp_ppp %>%
  quadratcount(.,nx = 6, ny = 6) %>%
  as.data.frame() %>%
  dplyr::count(Var1=Freq)%>%
  dplyr::rename(Freqquadratcount=n)
Qcount %>% 
  summarise_all(class)
sums <- Qcount %>%
  #calculate the total blue plaques (Var * Freq)
  mutate(total = Var1 * Freqquadratcount) %>%
  dplyr::summarise(across(everything(), sum))%>%
  dplyr::select(-Var1) 

lambda<- Qcount%>%
  #calculate lambda
  mutate(total = Var1 * Freqquadratcount)%>%
  dplyr::summarise(across(everything(), sum)) %>%
  mutate(lambda=total/Freqquadratcount) %>%
  dplyr::select(lambda)%>%
  pull(lambda)
```

```{r}
QCountTable <- Qcount %>%
  mutate(Pr=((lambda^Var1)*exp(-lambda))/factorial(Var1))%>%
  #now calculate the expected counts based on our total number of plaques
  #and save them to the table
  mutate(Expected= (round(Pr * sums$Freqquadratcount, 0)))

#Compare the frequency distributions of the observed and expected point patterns
plot(c(1,5),c(0,14), type="n",
xlab="Number of Very Health people in Manchester (Red=Observed,Blue=Expected)", 
     ylab="Frequency of Occurances")
points(QCountTable$Freqquadratcount, 
       col="Red", 
       type="o", 
       lwd=3)
points(QCountTable$Expected, col="Blue", 
       type="o", 
       lwd=3)
```
Observed shows the real data that was collected, which shows how common the "very healthy" population is in Manchester across different groups. For instance, the number of observations in the first group is greater and slowly goes down after that. Blue (Expected) shows the frequency that was found using a statistical model or a theory of expectations. The expected value goes up slowly as the group changes, which is clearly not the same as the measured value shown in red.

```{r DBSCAN's clustering}
library(dbscan)
library(fpc)

#first extract the points from the spatial data frame
points_todf <- manchester_data_very_sp %>%
coordinates(.) %>%
as.data.frame()

#now run the dbscan analysis
points_todf_DBSCAN <- points_todf %>%
fpc::dbscan(.,eps=1000,MinPts=50) 

#Eps=1000: Set the maximum proximity distance between points (1000 meters).MinPts=50: Set the minimum number of points for each cluster (at least 50 points form a cluster).

points_todf %>%
dbscan::kNNdistplot(.,k=50)
#Calculate the distance between each point and its 50th nearest neighbor
 
plot(points_todf_DBSCAN,points_todf,main="DBSCAN output",frame=F)
plot(boundary$geometry,add=T)
```
The picture displays DBSCAN's clustering results, but it is currently disorganized and unable to tell the difference between groups. This suggests that either the parameters (like eps and minPts) have not been optimized or the data distribution is not right for DBSCAN. DBSCAN works well with data that has big differences between areas that are thin and areas that are dense. If the data is too dense or spread out too evenly, the result might not be very good.
```{r}
colnames(merged_data)
```


```{r}
#Convert to sf object
manchester_data_very_sf <- st_as_sf(manchester_data_very_sp)
```

```{r}
colnames(manchester_data_very_sf)
```


```{r}
points_sf <- manchester_data_very_sf %>%
  clean_names()%>%
  mutate(area=st_area(.)) %>%#Computes the area of each community (in units matching the CRS).
  mutate(percentage=general_health_very_good_health/general_health_total_all_usual_residents)#Calculates the percentage people with very good health density by dividing the number of total all usual residents by the area of each community.
```

```{r}
tm_shape(points_sf)+
  tm_polygons("percentage",
              style="jenks",
              palette="PuOr",
              title="The percentage people with very good health")
```
This graph shows how the number of very healthy people in each area of Manchester is spread out across space. For illustration, a color gradient from orange (low percentage) to purple (high percentage) shows how the health level in different areas is very different. The areas with higher health ratios are mostly in the city center and some surrounding areas. These areas may have better economic conditions, better access to medical resources, and a better place to live. On the other hand, the areas with lower ratios are mostly on the southern and northern edges of the city, where resources may be scarce or the environment may not be good. In general, the level of health is not spread out evenly in Manchester. This means that places with low health levels should get more medical resources and government intervention.



```{r}
library(spdep)
coordsw <-manchester_data_very_sf %>%
  st_centroid()%>% 
  #Computes the geometric centroids for each community area in manchester_data_very_sp.The centroid represents the center point of each polygon.
  st_geometry() #Extracts the geometric information (coordinates) of the centroids.
plot(coordsw,axes=TRUE)

#make neighbours

community_nb <- manchester_data_very_sf %>%
  poly2nb(.,queen=T) #Generates an adjacency list for the polygons, describing which community areas are neighbors.
summary(community_nb)
#Plots the adjacency relationships on the map.
#Red lines connect centroids of adjacent community areas.
plot(community_nb,st_geometry(coordsw),col="red")
#Overlays the actual community boundaries (polygons) on the same map to provide spatial context.
plot(manchester_data_very_sp$geometry,add=T)
  
```

```{r}
#make weight matrix
community_nb.lw <- community_nb %>%
  nb2mat(.,style ="W")

sum(community_nb.lw)
```
This means there are 295 neighbor relationships between communities.


```{r}
#Converts the community adjacency list (community_nb) into a spatial weight matrix.
#style = "W": Creates a row-standardized weight matrix where the sum of each row equals 1.
community_nb.lw <- nb2listw(community_nb, zero.policy = TRUE)
```

```{r}
I_LWard_Global_Density <- points_sf %>%
  pull(percentage)%>%
  as.vector()%>%
  localmoran(.,community_nb.lw)#Computes Local Moran's I index for each community to analyze local spatial autocorrelation.
I_LWard_Global_Density
```

```{r}
points_sf <- points_sf %>%
  mutate(density_I = as.numeric(I_LWard_Global_Density[, "Ii"])) %>%
  mutate(density_Iz = as.numeric(I_LWard_Global_Density[, "Z.Ii"]))
```


```{r}
breaks1 <- c(-100, -2.58, -1.96, -1.65, 1.65, 1.96, 2.58, 1000)

library(RColorBrewer)
MoranColours <- rev(brewer.pal(8, "RdGy"))

tm_shape(points_sf) +
    tm_polygons("density_Iz",
        style = "fixed",
        breaks = breaks1,
        palette = MoranColours,
        midpoint = NA,
        title = "Local Moran's I, The percentage people with very good health")
```
The pattern of regional autocorrelation for the number of very healthy people in Manchester is shown by this Local Moran's I map. There are a lot of dark red areas (high high concentration areas) in the south and some central areas. These areas have a high health proportion and are surrounded by other high health proportion areas that may have better economic conditions, medical resources, and living conditions. On the other hand, there are a lot of light blue or gray areas (low low or low high concentration areas) on the edges of the city. These areas have low health levels and are affected by not having enough resources and infrastructure. This amazing difference in space shows how unevenly health is distributed in Manchester.



Report
"Analysis Report: Spatial Patterns of Very Healthy People in Manchester"

Project Scope
The main focus of this report is on the distribution and clustering of "very good health" percentages across different places in Manchester for the study of health patterns in space. The main goals are to look at how health measures are spread out in space, find important groups of high or low health percentages, and get ideas for how local governments can help fix health disparities. The main dataset, "manchester_data_very," has health and demographic data for Manchester at a local spatial resolution. Moran's I is used for spatial correlations, DBSCAN is used for clustering (but fails), and Quadrat Analysis is used for point pattern distribution. However, there are some problems, such as possible biases in the data collection and the limited spatial detail that is available. As part of the methods, spatial data is changed into forms that can be used, like centroids. Moran's I is used to test spatial autocorrelation, and Quadrat Analysis is used to test point pattern distribution.
Reading and Transforming Data
The main dataset was brought into R, and the data were read to make it work with current spatial tools. The dataset was then turned into a sf object. To make spatial grouping and adjacency analysis easier, polygons' centers were found. Importing data with st_read and turning it into a sf object with "st_as_sf" were two of the change steps. Then, "st_centroid" was used to find the center of each circle, and "st_coordinates" was used to get the coordinates of these centers into a data frame for further processing.
Wrangling Data
Data wrangling combined demographic and spatial geometries to include all necessary factors in one dataset. We chose density and geometry columns to narrow the research. This ensured the dataset was clean and suitable for the study.
Preparing Data for Analysis
To ensure space accuracy and compatibility with different methods, the data was checked and structured before analysis. To conduct autocorrelation studies, the coordinates were converted to a data frame and the dataset's integrity checked. Quadrat Analysis uses a grid framework to evaluate spatial distribution patterns.
Analysis
To determine health indicator distribution, this study uses three spatial methods. DBSCAN clustering was used to find groups with high very good health rates. Too many points made it difficult to set the eps and minPts parameters to meaningful amounts, so the method failed. We may need to try different clustering methods or get more data. Second, Moran's I autocorrelation examined health percentage changes over time. It found significant groups of high health percentages in central and southern Manchester and low health percentages in the city's edges. Third, Quadrat Analysis was used to see if the numbers of people who were in very good health were spread out in a random, regular, or clustered way. By splitting the study area into a grid of quadrats, the analysis showed that the data was not spread out randomly. There were clear clustering patterns that supported Moran's I results.
Outputs
The Local Moran's I map shows patterns of spatial autocorrelation, showing high-health clusters in the center and southern areas and low-health clusters in the edges. In addition to showing how the health percentages are spread out in space, the Quadrat Analysis result also shows clear clustering in the middle areas and some randomness in the edges, which supports Moran's I.
Conclusions
The study shows that health percentages are not spread out evenly across Manchester. There are large groups of places with high and low health measures. DBSCAN failed because of problems with data density and parameter tuning. Moran's I confirmed patterns of spatial autocorrelation, and Quadrat Analysis showed patterns of non-random distribution. But limits, like low data resolution, need to be thought about. To fix health disparities, policymakers should focus on low-health clusters on the edges of cities. To make the study more precise and accurate, socio-economic and environmental factors should be added. This all-around method will give us useful information for making sure that everyone in Manchester has the same health outcomes.







